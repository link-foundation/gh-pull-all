#!/usr/bin/env bun

// Universal test runner that supports both bun test and direct execution
// This script provides the interface required by the issue

import { promises as fs } from 'fs'
import { execSync } from 'child_process'
import path from 'path'

// Colors for console output
const colors = {
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  red: '\x1b[31m',
  cyan: '\x1b[36m',
  magenta: '\x1b[35m',
  dim: '\x1b[2m',
  bold: '\x1b[1m',
  reset: '\x1b[0m'
}

const log = (color, message) => console.log(`${colors[color]}${message}${colors.reset}`)

// Runtime detection
function detectRuntime() {
  if (typeof Bun !== 'undefined') return 'bun'
  return 'node'
}

async function runTests() {
  const runtime = detectRuntime()
  const startTime = Date.now()
  
  log('blue', `${colors.bold}ğŸ§ª GH-Pull-All Test Suite${colors.reset}`)
  log('cyan', `Runtime: ${runtime}`)
  
  let totalPassed = 0
  let totalFailed = 0
  
  try {
    // Run unit tests with bun test (faster)
    log('cyan', '\nğŸ“‹ Running unit tests...')
    try {
      const unitResult = execSync('bun test unit.test.mjs', {
        encoding: 'utf8',
        cwd: process.cwd()
      })
      
      // Parse bun test output
      const passMatch = unitResult.match(/(\d+) pass/)
      const failMatch = unitResult.match(/(\d+) fail/)
      
      const unitPassed = passMatch ? parseInt(passMatch[1]) : 0
      const unitFailed = failMatch ? parseInt(failMatch[1]) : 0
      
      totalPassed += unitPassed
      totalFailed += unitFailed
      
      if (unitFailed === 0) {
        log('green', `âœ… Unit tests: ${unitPassed} passed`)
      } else {
        log('red', `âŒ Unit tests: ${unitFailed} failed, ${unitPassed} passed`)
      }
    } catch (error) {
      log('red', `âŒ Unit tests failed to run: ${error.message}`)
      totalFailed += 1
    }
    
    // Run integration tests with direct execution (some are faster, some may be slow)
    log('cyan', '\nğŸ“‹ Running integration tests...')
    
    const fastTests = [
      'test-terminal-output.mjs',
      'test-threading.mjs',
      'test-cli-simple.mjs',
      'test-sorting.mjs',
      'test-progress-bar.mjs',
      'test-fixed-rendering.mjs',
      'test-terminal-rendering.mjs',
      'test-windowed-display.mjs'
    ]
    
    for (const testFile of fastTests) {
      try {
        const result = execSync(`./${testFile}`, {
          encoding: 'utf8',
          stdio: 'pipe',
          timeout: 10000 // 10 second timeout for fast tests
        })
        
        log('green', `âœ… ${testFile}: passed`)
        totalPassed += 1
      } catch (error) {
        log('red', `âŒ ${testFile}: failed`)
        if (error.stdout) {
          log('dim', `   ${error.stdout.slice(0, 100)}...`)
        }
        totalFailed += 1
      }
    }
    
    // Skip slow/problematic tests by default, but mention them
    const slowTests = [
      'test-integration.mjs',
      'test-terminal-width.mjs',
      'test-uncommitted-changes.mjs',
      'test-file-operations.mjs'
    ]
    
    log('yellow', `\nâš ï¸  Skipping slow integration tests: ${slowTests.join(', ')}`)
    log('dim', `   Run them individually if needed: ./test-integration.mjs`)
    
  } catch (error) {
    log('red', `ğŸ’¥ Test runner error: ${error.message}`)
    totalFailed += 1
  }
  
  // Summary
  const totalDuration = ((Date.now() - startTime) / 1000).toFixed(1)
  
  log('dim', '\n' + 'â”€'.repeat(80))
  log('blue', `\n${colors.bold}ğŸ“Š Test Suite Summary${colors.reset}`)
  
  if (totalPassed > 0) {
    log('green', `âœ… Passed: ${totalPassed} tests`)
  }
  
  if (totalFailed > 0) {
    log('red', `âŒ Failed: ${totalFailed} tests`)
  }
  
  log('blue', `â±ï¸  Total time: ${totalDuration}s`)
  
  if (totalFailed === 0) {
    log('green', `\nğŸ‰ All tests passed!`)
    log('magenta', 'âœ¨ Features validated:')
    log('magenta', '   â€¢ Unit tests for core functionality')
    log('magenta', '   â€¢ CLI argument parsing and validation')
    log('magenta', '   â€¢ Threading options and concurrency')
    log('magenta', '   â€¢ Terminal output modes')
    log('magenta', '   â€¢ Cross-runtime compatibility (bun/node)')
  } else {
    log('red', `\nğŸ’¥ ${totalFailed} test(s) failed. Please review and fix the issues.`)
    process.exit(1)
  }
}

// Support both direct execution and module import
if (import.meta.url === `file://${process.argv[1]}`) {
  runTests().catch(error => {
    log('red', `ğŸ’¥ Test runner failed: ${error.message}`)
    process.exit(1)
  })
}